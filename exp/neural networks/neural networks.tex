\documentclass{../exp}
\usepackage{../../ikany}

\title{Neural Networks}

\begin{document}
\maketitle
\tableofcontents

The AI paradigm changes when a new approximating method is discovered.

\section{Motivations}


\subsection{Statistical model}
The following is not mathematically sound.
\begin{defn}
A \emph{statistical model} is an approximation scheme for unknown probability distribution.
\end{defn}
In particular, the general purpose of many statistical models is to estimate the joint probability distribution of two random variables $X$ and $Y$.
The joint probability distrbution contains data about relation between $X$ and $Y$.
Suppose our goal is to obtain the most possible value of $Y$ when given $X=x$, and we have estimated the joint distribution function $f_{X,Y}$.
Then, the function $y\mapsto f_{X,Y}(x,y)$ describes the distribution of $Y|X=x$, so what we wanted is reasonably defined as
\[\hat y=\argmax_yf_{X,Y}(x,y).\]

\subsection{Statistical mechanics}

\section{Models}

\subsection{Random fields}
\begin{defn}[Random field]
A \emph{random field} is a set of random variables parametrized by a topological space or a (directed or undirected)graph.
\end{defn}
\begin{defn}
In this note, we will call the random fields on a graph as \emph{networks}.
\end{defn}
Actually, networks and graphs are often used as synonyms.

\begin{ex}[Markov chain]
Let $G=(V,E)$ be a directed graph defined by
\[V=\Z_{\ge0},\quad E=\{(t,t+1)\}_{t\in V},\]
that is, an element $t\in V$ denotes the time $t$.

Let $\cS$ be a finite set of states such that every subset is measurable.
Then, the set of $\cS$-valued random variables $\{X_t\}_{t\in V}$ indexed by $V$ defines a random field.
The Markov property is given by
\[X_t\indep X_s\mid X_{t-1}\]
for $s\le t$.
Since $\cS$ is finite, alternatively we may rewrite it by
\[\Pr(X_t=x_t\mid X_{t-1}=x_{t-1})=\Pr(X_t=x_t\mid X_{t-1}=x_{t-1},\cdots,X_0=x_0).\]
\end{ex}

\begin{ex}[Maxwell-Boltzman distribution]
Let $G=(V,E)$ be a graph defined by
\[V=\{n\}_{n=1}^N,\quad E=\mt\]
for a large natural number $N$; the set $V$ is considered to be the set of ideal gas particles.
Define the space of microstates $\cS=\Z_x^3\x\Z_p^3$, which embodies the discretized phase space.
At each particle $n\in V$, an $\cS$-valued random variable denoted by $X_n$ is attached.

Let $m>0$ be a constant.
Define the \emph{Boltzmann factor} as a function $\phi:\R_{>0}\x V\to\R$ such that
\[\phi(\beta,i):=e^{-\beta E_i},\]
where $\beta=\frac1{k_BT}>0$ is called \emph{coldness} and the \emph{energy function} $E:\cS\to\R$ is defined by
\[E(x,p):=\frac{\|p\|^2}{2m}.\]

The assumption for Boltzmann factors states that given $\beta$, the probability for a particle to be in the state $i$ is proportional to the Boltzmann factor: 
\[\Pr(X_n=i)\propto e^{-\beta E_i}\]
for each state $i\in\cS$ and particle $n\in V$.
Thus, we can write
\[\Pr(X_n=i)=\frac{e^{-\beta E_i}}{\sum_{j=1}^Ne^{-\beta E_j}}=:\frac1{Z(\beta)}\,e^{-\frac\beta{2m}\|p_i\|^2}.\]
The denominator $Z$ is called the \emph{partition function}.
Note that it depends on the data of the Boltzmann factor.
% X가 베타인 것이 아니라 에너지가 X,Y에 모두 의존한다고 보는 게 맞는 것 같다.
% 그리고 베타를 조정해서 학습을 하는 것이다.
% 그러므로 위의 내용을 고쳐야 한다.
\end{ex}


\subsection{Bayesian networks}


\begin{defn}[Bayesian network]
Let $G$ be a directed acyclic graph.
\end{defn}
The graph acts as a parameter space.
We want to investigate mutual effects among the paramtrized random variables.
\begin{thm}[Factorization of probablity]

\end{thm}

\begin{ex}[NBC, Naive Bayesian Classifier]
\end{ex}
\begin{ex}[HMM, Hidden Markov Model]
\end{ex}


\subsection{Markov networks}

\begin{defn}[Markov network]
\end{defn}
Markov networks are sometimes called MRF, Markov random field.

\begin{ex}[CRF, Conditional Random Field]
Consider a network with a graph $G$ such that vertices are divided into two classes.
\end{ex}

\subsection{Neural networks}
Probabilistic graphical models provide effective explanations of the neural networks, but neural networks are not confined only to graphical models.
\begin{defn}[Neural network]
\emph{Neural network} cannot be defined mathematically.
It indicates statistical models that can solve problems with a collection of artificial neurons by adjusting connection strength among them.
\end{defn}

\begin{ex}[MLP, Multi-layer Perceptron]

\end{ex}

\begin{ex}[RNN, Recurrent Neural Network]

\end{ex}

\section{Inference}
\subsection{Viterbi algorithm}
\section{Learning}
\subsection{Gradient descent method}



\subsection{Back propagation}
Backpropagation refers to algorithms to train the weight matrices for minimizing the cost function $J$, which does not depend explicitly on any variables except the last layer vector $a^{(n)}$.
However, since $J$ is a function of the weight matrices implicitly, via $a^{(n)}$, we may find the representation of the gradiant of $J$ as viewing it as a function on the space of weight matrices of each given layer.
In other words, we want to find the coefficients of the differential form $dJ$ on the basis $\{dW_{ij}^{(n-1)}\}_{i,j}$, $\{dW_{jk}^{(n-2)}\}_{j,k}$, or $\{dW_{kl}^{(n-3)}\}_{k,l}$, and so on.

Recall the definitions:
\[a_i^{(n)}=\sigma\left(\sum_jW_{ij}^{(n-1)}a_j^{(n-1)}\right).\]
Since the derivative of the sigmoid function is given by $\sigma'=\sigma-\sigma^2$, we can compute the following auxiliary relations
\[\pd{a_i^{(n)}}{a_j^{(n-1)}}=h(a_i^{(n)})W_{ij}^{(n-1)}\c{and}\pd{a_i^{(n)}}{W_{i'j}^{(n-1)}}=\delta_{ii'}h(a_i^{(n)})a_j^{(n-1)},\]
where $h(x)=x-x^2$.

Then, we can compute
\[dJ=\sum_i\pd{J}{a_i^{(n)}}\sum_j\pd{a_i^{(n)}}{W_{ij}^{(n-1)}}\,dW_{ij}^{(n-1)}=\sum_{i,j}\pd{J}{a_i^{(n)}}h(a_i^{(n)})a_j^{(n-1)}\,dW_{ij}^{(n-1)},\]
which implies
\[\del J(W^{(n-1)})=\left[\pd{J}{a_i^{(n)}}h(a_i^{(n)})a_j^{(n-1)}\right]\pd{W_{ij}^{(n-1)}}.\]
Note that it is a function of $a_i$ and $a_j$.
The gradient descent method will take
\[{W_{ij}^{(n-1)}}^+:=W_{ij}^{(n-1)}-\alpha\cdot\pd{J}{a_i^{(n)}}h(a_i^{(n)})a_j^{(n-1)}\]
with a proper parameter $\alpha>0$.

By the same reason,
\begin{align*}
dJ&=\sum_{i,j,k}\pd{J}{a_i^{(n)}}\pd{a_i^{(n)}}{a_j^{(n-1)}}\pd{a_j^{(n-1)}}{W_{jk}^{(n-2)}}\,dW_{jk}^{(n-2)}\\
&=\sum_{i,j,k}\pd{J}{a_i^{(n)}}\cdot h(a_i^{(n)})W_{ij}^{(n-1)}\cdot h(a_j^{(n-1)})a_k^{(n-2)}\,dW_{jk}^{(n-2)},
\end{align*}
which implies
\[\del J(W^{(n-2)})=\left[\sum_i\pd{J}{a_i^{(n)}}\cdot h(a_i^{(n)})W_{ij}^{(n-1)}\cdot h(a_j^{(n-1)})a_k^{(n-2)}\right]\pd{W_{jk}^{(n-2)}}.\]
Therefore, the gradient descent method will take
\begin{align*}
{W_{jk}^{(n-2)}}^+:&=W_{jk}^{(n-2)}-\alpha\cdot\sum_i\pd{J}{a_i^{(n)}}h(a_i^{(n)})W_{ij}^{(n-1)}h(a_j^{(n-1)})a_k^{(n-2)}\\
&=W_{jk}^{(n-2)}+(1-a_j^{(n-1)})a_k^{(n-2)}\sum_i({W_{ij}^{(n-1)}}^+-W_{ij}^{(n-1)})W_{ij}^{(n-1)}.
\end{align*}
In similar way,
\[{W_{kl}^{(n-3)}}^+:=W_{kl}^{(n-3)}+(1-a_k^{(n-2)})a_l^{(n-3)}\sum_i({W_{jk}^{(n-2)}}^+-W_{jk}^{(n-2)})W_{jk}^{(n-2)}(?)\]




\subsection{Maximum likelihood estimate}
\begin{defn}
Let $f$ be a distribution function on a measure space $X$.
Let $\{f_\theta\}_\theta$ be a parametrized family of distrubution functions on $X$.
The \emph{likelihood} $L_n(\theta):\Omega^n\to\R_{\ge0}$ for a fixed parameter $\theta$ is a random variable defined by
\[L_n(\theta):=\prod_{i=1}^nf_\theta(x_i)\]
where $\{x_i\}_i$ is a family of i.i.d. $X$-valued random variables with a distriburion $f$.
\end{defn}
The objective of the likelihood function is to find $\theta$ such that $f_\theta$ approximates the unknown distribution $f$.
Write
\[\frac1n\log L_n(\theta)=\frac1n\sum_{i=1}^n\log f_\theta(x_i).\]
By the law of large numbers, $\frac1n\log L_n(\theta)$ converges to a constant function
\[\E(\log f_\theta(x))=\int_Xf\log f_\theta\]
in measure as $n\to\oo$.
This constant function is exactly what we call \emph{cross entropy}.

The \emph{Kullback-Leibler divergence} is a kind of asymmetric distance function defined from the difference with cross entropy
\[D_{KL}(f\|f_\theta):=\int_Xf\log f-\int_Xf\log f_\theta.\]
It is proved to be always nonnegative by the Jensen inequality: 
\[\int_Xf\log f_\theta-\int_Xf\log f=\int_Xf\log\frac{f_\theta}f\le\log\left(\int_Xf\frac{f_\theta}f\right)=0.\]
Here, we exclude the region $f=0$ from the integration region.
Then, we can say, bigger $L_n(\theta)$ is, closer $f_\theta$ and $f$ are.












\iffalse
\section{Generative adversarial networks}
Let $X$ be the set of all images having a given pixel size.
Suppose the data distribution $p_{data}$ on $X$ which embodies learning materials is given.
If $x\in X$ is an image that looks like a real human face, then the distribution(mass) function $p_{data}$ has nonnegligible values near the point $x$.
We cannot describe the distribution function $p_{data}$ completely, but only can sample from it.

Let $p_g$ be a distribution on $X$.
The generator $G:\Omega\to X$ is just an arbitrarily taken random variable satisfying $p_g$ for sampling.
The discriminator $D:X\to[0,1]$ is a function
Our purpose is to construct a new method for approximating $p_g\to p_{data}$ by simultaneously updating the discriminator function $D$.

Let $x_i\sim p_{data}$ and $z\sim p_g$ be random variables $\Omega\to X$.
Let $D$ maximize
\[\log D(x)+\log(1-D(z))\]
and $p_g$ minimize
\[\log(1-D(z)).\]


Balancing the convergence rates between $p_g$ and $D$ is important.
\fi



\end{document}