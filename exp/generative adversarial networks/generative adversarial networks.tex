\documentclass{../exp}
\usepackage{../../ikany}

\title{Generative Adversarial Networks}

\begin{document}
\maketitle

The AI paradigm changes when a new approximating method is discovered.

\section{Maximum likelihood estimate}
\begin{defn}
Let $\{f_\theta\}_\theta$ be a parametrized family of distrubution functions on a measure space $X$.
The \emph{likelihood} $L_n(\theta):\Omega^n\to\R_{\ge0}$ for a fixed parameter $\theta$ is a random variable defined by
\[L_n(\theta):=\prod_{i=1}^nf_\theta(x_i)\]
where $\{x_i\}_i$ is a family of i.i.d. $X$-valued random variables with a distriburion $f$ different from $f_\theta$.
\end{defn}
The objective of the likelihood function is to find $\theta$ such that $f_\theta$ approximates the unknown distribution $f$.
Write
\[\frac1n\log L_n(\theta)=\frac1n\sum_{i=1}^n\log f_\theta(x_i).\]
By the law of large numbers, $\frac1n\log L_n(\theta)$ converges to a constant function
\[\E(\log f_\theta(x))=\int_Xf\log f_\theta\]
in measure as $n\to\oo$.

Note that
\begin{align*}
\int_Xf\log f_\theta&\le\int_Xf(f_\theta-1)\\
&=\frac12(\|f\|_2^2+\|f_\theta\|_2^2-\|f-f_\theta\|_2^2)-1.
\end{align*}
Intuitively, bigger $L_n(\theta)$ is, closer $f_\theta$ and $f$ are.


\section{Gradient descent method}
ascending stochastic gradient


\section{Minimax game}

Minimax is a \emph{decision policy} in a competitive game.

\section{Generative adversarial networks}
Let $X$ be the set of all images having a given pixel size.
Suppose the data distribution $p_{data}$ on $X$ which embodies learning materials is given.
If $x\in X$ is an image that looks like a real human face, then the distribution(mass) function $p_{data}$ has nonnegligible values near the point $x$.
We cannot describe the distribution function $p_{data}$ completely, but only can sample from it.

Let $p_g$ be a distribution on $X$.
The generator $G:\Omega\to X$ is just an arbitrarily taken random variable satisfying $p_g$ for sampling.
The discriminator $D:X\to[0,1]$ is a function
Our purpose is to construct a new method for approximating $p_g\to p_{data}$ by simultaneously updating the discriminator function $D$.

Let $x_i\sim p_{data}$ and $z\sim p_g$ be random variables $\Omega\to X$.
Let $D$ maximize
\[\log D(x)+\log(1-D(z))\]
and $p_g$ minimize
\[\log(1-D(z)).\]


Balancing the convergence rates between $p_g$ and $D$ is important.




\end{document}